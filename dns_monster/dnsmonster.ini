[general]
# Garbage Collection interval for tcp assembly and IP defragmentation
gctime = 10s

# Duration to calculate interface stats
capturestatsdelay = 1s

# Mask IPv4s by bits. 32 means all bits of IP are saved in DB
masksize4 = 32

# Mask IPv6s by bits. 128 means all bits of IP are saved in DB
masksize6 = 128

# Name of the server used to index the metrics
servername = dnsmonster-server

# Set debug log format
logformat = text

# Set debug log level
# 0: PANIC, 1: ERROR, 2: WARN, 3: INFO, 4: DEBUG
loglevel = 3

# Size of the result processor channel
resultchannelsize = 100000

# Write CPU profile to file (optional)
cpuprofile =

# Write memory profile to file (optional)
memprofile =

# GOMAXPROCS variable (-1 means use all available CPUs)
gomaxprocs = -1

# Limit of packets logged to Elasticsearch every iteration (0 means disabled)
packetlimit = 0

# Skip outputting domains matching items in the CSV file path (optional)
skipdomainsfile =

# Hot-Reload skipdomainsfile interval
skipdomainsrefreshinterval = 1m0s

# Allow Domains logic input file (optional)
allowdomainsfile =

# Hot-Reload allowdomainsfile interval
allowdomainsrefreshinterval = 1m0s

# Skip TLS verification when making HTTPS connections
# Set to true if using self-signed certificates
skiptlsverification = true


[capture]
# Device used to capture network traffic
devname = ${WIFI_INTERFACE}

# Port to filter packets (DNS default port is 53)
port = 53

# Capture Sampling ratio (1:1 processes all packets)
sampleratio = 1:1

# BPF filter applied to the packet stream to capture only DNS traffic
filter = udp port 53

# Use AFPacket for live captures (set to true if supported and needed)
useafpacket = false

# Do not put the interface in promiscuous mode
nopromiscuous = false

[file_output]
# What should be written to file
# 0: Disable Output
# 1: Enable Output without any filters
# 2: Enable Output and apply skipdomains logic
# 3: Enable Output and apply allowdomains logic
# 4: Enable Output and apply both skip and allow domains logic
fileoutputtype = 1

# Path to output folder (ensure this directory exists and has write permissions)
fileoutputpath = /var/log/dnsmonster/

# Interval to rotate the file in cron format (e.g., daily at midnight)
fileoutputrotatecron = 0 0 * * *

# Number of rotated files to keep (7 keeps one week's logs)
fileoutputrotatecount = 7

# Output format for file
# Options: json, csv, csv_no_header, gotemplate
fileoutputformat = json

# Go Template to format the output (only needed if using gotemplate format)
# fileoutputgotemplate = {{.}}

[elastic_output]
# What should be written to Elasticsearch
# 0: Disable Output
# 1: Enable Output without any filters
# 2: Enable Output and apply skipdomains logic
# 3: Enable Output and apply allowdomains logic
# 4: Enable Output and apply both skip and allow domains logic
ElasticOutputType = 1

# Elasticsearch endpoint address, including authentication credentials
# Format: https://username:password@host:port
ElasticOutputEndpoint = https://${ELK_USERNAME}:${ELK_PASSWORD}@${ELK_URL}:${ELK_PORT}

# Elasticsearch index name
ElasticOutputIndex = ${DNSMONSTER_ELASTIC_OUTPUT_INDEX}

# Send data to Elasticsearch in batch sizes
ElasticBatchSize = 1000

# Interval between sending results to Elasticsearch if batch size is not filled
ElasticBatchDelay = 1s
